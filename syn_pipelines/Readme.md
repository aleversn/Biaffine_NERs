## LLM DA for Knowledge Fusion for Rich and Efficient Extraction Model

## ğŸ§­ ä½¿ç”¨æŒ‡å—

### ğŸ”¨ å®‰è£…ä¾èµ–

å¦‚æœåŒæ—¶éœ€è¦ç”¨åˆ°`GLM3`, `GLM4`, `QWen2`å’Œ`Llama3`ç­‰æ¨¡å‹, å› æ­¤éœ€è¦å®‰è£…ä¸¤ä¸ªcondaç¯å¢ƒä»¥å…¼å®¹æ–°æ—§ç‰ˆæœ¬æ¨¡å‹ã€‚å…¶ä¸­`GLM3`å’Œå…¶å®ƒæ¨¡å‹å¯¹`transformers`åº“ç‰ˆæœ¬çš„è¦æ±‚ä¸åŒ, å› æ­¤ éœ€è¦åˆ†åˆ«å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„`transformers`åº“ã€‚

å¦‚æœä½ åªéœ€ä½¿ç”¨åˆ°`GLM3`æˆ–æ˜¯é™¤`GLM3`å¤–çš„å…¶ä»–æ¨¡å‹ï¼Œå¯ä»¥åªé€‰æ‹©ä¸€ç§condaç¯å¢ƒã€‚

1. åˆ›å»ºä¸€ä¸ªcondaç¯å¢ƒ, ä¾‹å¦‚`llm`:

``` bash
conda create -n llm python=3.10
conda activate llm
```

2. å®‰è£…æ‰€éœ€ä¾èµ–:

- é’ˆå¯¹`GLM3`:

```bash
pip install protobuf transformers==4.30.2 cpm_kernels torch>=2.0 gradio mdtex2html sentencepiece accelerate
```

- é’ˆå¯¹å…¶ä»–æ¨¡å‹

```bash
pip install protobuf transformers==4.44 cpm_kernels torch>=2.0 gradio mdtex2html sentencepiece accelerate tiktoken
```

### ğŸš€ è¿è¡ŒPipeline

#### å®šä¹‰

- LLM DAä¸­åˆ©ç”¨LLMå¯¹åŸå§‹æ•°æ®è¿›è¡Œ`entity`å’Œ`pos`æ‰©å±•æ ‡æ³¨, æœ€ç»ˆç”Ÿæˆ`fusion`æ•°æ®
- LLM DAè¿˜å¯¹åŸå§‹æ•°æ®è¿›è¡Œå®ä½“æè¿°åˆæˆ, æœ€ç»ˆç”Ÿæˆ`syn_fusion`æ•°æ®

> å¦‚æœä½ æƒ³è¦åœ¨jupyter kernelä¸­è¿è¡Œä»£ç , è¯·å°†`cmd_args`è®¾ä¸º`False`.

1. æ ‡æ³¨æ‰©å±•`entity`å’Œ`pos`

```bash
python syn_pipelines/s1_predict_data.py \
    --n_gpu=0 \
    --skip=-1 \
    --file_dir="./data/few_shot" \
    --file_name=weibo \
    --save_type_name=GLM4 \
    --model_from_pretrained="/home/lpc/models/glm-4-9b-chat/" \
    --batch_size=20 \
    --mode=entity
```

- `n_gpu`: æŒ‡å®šä½¿ç”¨çš„GPUç´¢å¼• (é»˜è®¤ä¸º0)
- `skip`: è·³è¿‡å·²å¤„ç†æ–‡ä»¶çš„æ•°é‡(é»˜è®¤ä¸º-1, å³å…¨éƒ¨å¤„ç†)
- `file_dir`: æ‰€æœ‰æ•°æ®é›†çš„æ ¹ç›®å½•(é»˜è®¤ä¸º"./data/few_shot")
- `file_name`: æ•°æ®é›†åç§°, å¦‚ "weibo", ä½ å¿…é¡»ç¡®ä¿`./data/few_shot/weibo`åº•ä¸‹æœ‰`train_1000.jsonl`è¿™ä¸ªæ–‡ä»¶
- `save_type_name`: è¦ä¿å­˜çš„æ•°æ®æ–‡ä»¶å¤¹å‰ç¼€ (é»˜è®¤ä¸º"GLM4")
- `model_from_pretrained`: é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„
- `batch_size`: æ‰¹æ¬¡å¤§å°, é»˜è®¤ä¸º20
- `mode`: æ¨¡å¼(entity/pos), é»˜è®¤ä¸º"entity"

ä¸€èˆ¬æ¥è¯´, å¯¹äºä¸æ€ä¹ˆéœ€è¦ä¿®æ”¹çš„å‚æ•°, å¯ä»¥ç›´æ¥ä½¿ç”¨é»˜è®¤å€¼å³å¯ã€‚

2. ä¸°å¯Œ`entity`è§£é‡Šç”Ÿæˆåˆæˆæ•°æ®

```bash
python syn_pipelines/s2_continous_generation.py \
    --n_gpu= 0 \
    --file_dir="./data/few_shot" \
    --file_name=weibo \
    --save_type_name=GLM4 \
    --model_from_pretrained="/home/lpc/models/glm-4-9b-chat/" \
    --batch_size=40 \
```

3. æ ‡æ³¨åˆæˆæ•°æ®çš„æ‰©å±•`entity`å’Œ`pos`

å‚æ•°å’Œæ­¥éª¤1ä¸€æ ·

```bash
python syn_pipelines/s3_predict_syn_data.py \
    --n_gpu=0 \
    --skip=-1 \
    --file_dir="./data/few_shot" \
    --file_name=weibo \
    --save_type_name=GLM4 \
    --model_from_pretrained="/home/lpc/models/glm-4-9b-chat/" \
    --batch_size=20 \
    --mode=entity
```

4. åˆ†å‰²æ•°æ®, å°†æ•°æ®è‡ªåŠ¨æŒ‰`25%`, `50%`, `100%`åˆ†ç±»

```bash
python syn_pipelines/s4_split_data.py \
    --file_dir="./data/few_shot" \
    --file_name=weibo \
    --save_type_name=GLM4
```

5. åˆ©ç”¨æ­¥éª¤`1`å’Œæ­¥éª¤`3`çš„æ ‡æ³¨æ•°æ®åˆå¹¶åˆ°å¯¹åº”æºæ•°æ®ä¸­, å¹¶åˆ†åˆ«ç”Ÿæˆåˆå¹¶çš„`fusion`æ ‡ç­¾å’Œ`syn_fusion`æ ‡ç­¾

```bash
python syn_pipelines/s5_merge_data.py \
    --file_dir="./data/few_shot" \
    --file_name=weibo \
    --is_syn=0  \
    --save_type_name=GLM4 \
    --label_prefix='' \
    --entity_label='./data/fusion_knowledge/entity_label.json' \
    --pos_label='./data/fusion_knowledge/pos_label.json'
```

- `is_syn`: æ˜¯å¦æ˜¯åˆæˆæ•°æ®(0è¡¨ç¤ºä¸æ˜¯, 1è¡¨ç¤ºæ˜¯)
- `label_prefix`: æ ‡ç­¾å‰ç¼€(å¦‚æœæ‰©å±•æ ‡ç­¾ä¸åŸå§‹æ ‡ç­¾æœ‰é‡å, å»ºè®®è®¾ç½®å‰ç¼€)
- `entity_label`: å®ä½“æ ‡ç­¾æ ‡å‡†åŒ–æ–‡ä»¶è·¯å¾„
- `pos_label`: è¯æ€§æ ‡ç­¾æ ‡å‡†åŒ–æ–‡ä»¶è·¯å¾„

6. åˆå¹¶`fusion`æ ‡ç­¾å’Œ`syn_fusion`æ ‡ç­¾

```bash
python syn_pipelines/s6_combine_syn_fusion_label.py \
    --file_dir="./data/few_shot" \
    --file_name=weibo \
    --save_type_name=GLM4
```

7. åˆ©ç”¨NERæ¨¡å‹é¢„æµ‹åˆæˆæ•°æ®çš„åŸå§‹ç›®æ ‡æ ‡ç­¾

åœ¨æ‰§è¡Œè¿™ä¸€æ­¥ä¹‹å‰, ä½ å¯ä»¥å…ˆå¯¹`fusion`æ•°æ®é›†è¿›è¡Œè®­ç»ƒäº†, è®­ç»ƒåå†åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹æ¥æ ‡æ³¨åˆæˆæ•°æ®é›†çš„æ ‡ç­¾

```bash
python syn_pipelines/s7_pred_syn_data.py \
    --file_dir="./data/few_shot" \
    --file_name=weibo \
    --save_type_name=GLM4 \
    --from_pretrained='/home/lpc/models/chinese-bert-wwm-ext/' \
    --model_from_pretrained='/home/lpc/repos/Biaffine_NERs/save_model/CNNNER-youku_1000_fusion_sota/cnnner_best' \
    --batch_size=4
```

- `from_pretrained`: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
- `model_from_pretrained`: æ¨¡å‹ä¿å­˜è·¯å¾„(ä¹‹æ‰€ä»¥åˆ†ä¸ºä¸¤ä¸ªè·¯å¾„æ˜¯å› ä¸ºä¿å­˜æ¨¡å‹å¯èƒ½æ²¡åŒ…å«tokenizerçš„é…ç½®æ–‡ä»¶)

8. åˆ©ç”¨æ­¥éª¤`1`,æ­¥éª¤`3`å’Œæ­¥éª¤`7`çš„æ ‡æ³¨æ•°æ®åˆå¹¶åˆ°å¯¹åº”æºæ•°æ®ä¸­, å¹¶åˆ†åˆ«ç”Ÿæˆåˆå¹¶çš„`fusion`æ ‡ç­¾å’Œ`syn_fusion`æ ‡ç­¾, å¹¶æœ€ç»ˆå°†`fusion`æ•°æ®åˆå¹¶åˆ°`syn_fusion`æ•°æ®ä¸­

```bash
python syn_pipelines/s8_process_label_and_combine.py \
    --file_dir="./data/few_shot" \
    --file_name=weibo \
    --is_syn=0  \
    --save_type_name=GLM4 \
    --label_prefix='' \
    --entity_label='./data/fusion_knowledge/entity_label.json' \
    --pos_label='./data/fusion_knowledge/pos_label.json'
```